
@misc{ai2019,
  title = {Reinforcement {{Learning}} Algorithms \textemdash{} an Intuitive Overview},
  author = {AI, SmartLab},
  year = {2019},
  month = feb,
  journal = {Medium},
  abstract = {Author: Robert Moni},
  howpublished = {https://smartlabai.medium.com/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/KINLECZW/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc.html}
}

@article{arnstein1969,
  title = {A {{Ladder Of Citizen Participation}}},
  author = {Arnstein, Sherry R.},
  year = {1969},
  month = jul,
  journal = {Journal of the American Institute of Planners},
  volume = {35},
  number = {4},
  pages = {216--224},
  issn = {0002-8991},
  doi = {10.1080/01944366908977225},
  abstract = {The heated controversy over ``citizen participation,'' ``citizen control'', and ``maximum feasible involvement of the poor,'' has been waged largely in terms of exacerbated rhetoric and misleading euphemisms. To encourage a more enlightened dialogue, a typology of citizen participation is offered using examples from three federal social programs: urban renewal, anti-poverty, and Model Cities. The typology, which is designed to be provocative, is arranged in a ladder pattern with each rung corresponding to the extent of citizens' power in determining the plan and/or program.}
}

@misc{aronson2018,
  title = {A {{Word About Evidence}}: 4. {{Bias}}\textemdash Etymology and Usage},
  shorttitle = {A {{Word About Evidence}}},
  author = {Aronson, Jeff},
  year = {2018},
  journal = {Catalogue of Bias},
  howpublished = {https://catalogofbias.org/2018/04/10/a-word-about-evidence-4-bias-etymology-and-usag/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/5LNNHN5N/a-word-about-evidence-4-bias-etymology-and-usag.html}
}

@article{ashmore2019,
  title = {Assuring the {{Machine Learning Lifecycle}}: Desiderata, {{Methods}}, and {{Challenges}}},
  shorttitle = {Assuring the {{Machine Learning Lifecycle}}},
  author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
  year = {2019},
  month = may,
  journal = {arXiv:1905.04223 [cs, stat]},
  eprint = {1905.04223},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our paper provides a comprehensive survey of the state-of-the-art in the assurance of ML, i.e. in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e. of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The paper begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering,Statistics - Machine Learning},
  file = {/Users/cburr/Zotero/storage/9BAJE732/Ashmore et al. - 2019 - Assuring the Machine Learning Lifecycle Desiderat.pdf;/Users/cburr/Zotero/storage/QIH9HG6C/Ashmore et al. - 2019 - Assuring the Machine Learning Lifecycle Desiderat.pdf}
}

@misc{ball2020,
  title = {The Real Story of {{Cambridge Analytica}} and {{Brexit}} | {{The Spectator}}},
  author = {Ball, James},
  year = {2020},
  month = oct,
  abstract = {In July 2018, Elizabeth Denham \textendash{} the woman in charge of enforcing the UK's laws on data protection \textendash{} appeared on the Today programme, and made a stark allegation. 'In 2014 and 2015, the Facebook platform allowed an app\ldots{} that ended up harvesting 87 million profiles of users around the world that was...},
  howpublished = {https://www.spectator.co.uk/article/were-there-any-links-between-cambridge-analytica-russia-and-brexit-},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/3TG38H22/were-there-any-links-between-cambridge-analytica-russia-and-brexit-.html}
}

@article{barnhart1989,
  title = {{{DOE Human Genome Project}}},
  author = {Barnhart, Benjamin},
  year = {1989},
  journal = {Human Genome Quarterly},
  volume = {1},
  number = {1},
  file = {/Users/cburr/Zotero/storage/JU5MNAFY/Vol1No1.pdf}
}

@book{beauchamp2013,
  title = {Principles of Biomedical Ethics},
  author = {Beauchamp, Tom L and Childress, James F},
  year = {2013},
  edition = {Seventh},
  publisher = {{Oxford University Press}},
  address = {{New York, N.Y.}},
  isbn = {978-0-19-992458-5},
  langid = {english},
  keywords = {Ethics; Medical,Medical ethics}
}

@book{bingham2011,
  title = {The Rule of Law},
  author = {Bingham, T. H},
  year = {2011},
  publisher = {{Allen Lane}},
  address = {{London; New York}},
  isbn = {978-0-14-196201-6},
  langid = {english},
  annotation = {OCLC: 793208482}
}

@book{bridgstock1998,
  title = {Science, Technology, and Society: An Introduction},
  shorttitle = {Science, Technology, and Society},
  author = {Bridgstock, Martin},
  year = {1998},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, U.K. ; New York}},
  isbn = {978-0-521-58320-6 978-0-521-58735-8},
  langid = {english},
  lccn = {Q175.5 .S3738 1998},
  keywords = {Science,Science and state,Social aspects,Technology,Technology and state},
  file = {/Users/cburr/Zotero/storage/AEF9P33J/AEF9P33J.pdf}
}

@misc{bronshtein2020,
  title = {Train/{{Test Split}} and {{Cross Validation}} in {{Python}}},
  author = {Bronshtein, Adi},
  year = {2020},
  month = mar,
  journal = {Medium},
  abstract = {Hi everyone! After my last post on linear regression in Python, I thought it would only be natural to write a post about Train/Test Split\ldots},
  howpublished = {https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7A7E6HKF/train-test-split-and-cross-validation-in-python-80b61beca4b6.html}
}

@article{burr2019,
  title = {Can {{Machines Read}} Our {{Minds}}?},
  author = {Burr, Christopher and Cristianini, Nello},
  year = {2019},
  month = sep,
  journal = {Minds and Machines},
  volume = {29},
  number = {3},
  pages = {461--494},
  issn = {0924-6495, 1572-8641},
  doi = {10.1007/s11023-019-09497-4},
  abstract = {We explore the question of whether machines can infer information about our psychological traits or mental states by observing samples of our behaviour gathered from our online activities. Ongoing technical advances across a range of research communities indicate that machines are now able to access this information, but the extent to which this is possible and the consequent implications have not been well explored. We begin by highlighting the urgency of asking this question, and then explore its conceptual underpinnings, in order to help emphasise the relevant issues. To answer the question, we review a large number of empirical studies, in which samples of behaviour are used to automatically infer a range of psychological constructs, including affect and emotions, aptitudes and skills, attitudes and orientations (e.g. values and sexual orientation), personality, and disorders and conditions (e.g. depression and addiction). We also present a general perspective that can bring these disparate studies together and allow us to think clearly about their philosophical and ethical implications, such as issues related to consent, privacy, and the use of persuasive technologies for controlling human behaviour.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7929S8WK/Burr and Cristianini - 2019 - Can Machines Read our Minds.pdf;/Users/cburr/Zotero/storage/E4IS9IWE/Burr and Cristianini - 2019 - Can Machines Read our Minds.pdf}
}

@article{burr2021a,
  title = {Ethical {{Assurance}}: A Practical Approach to the Responsible Design, Development, and Deployment of Data-Driven Technologies},
  shorttitle = {Ethical {{Assurance}}},
  author = {Burr, Christopher and Leslie, David},
  year = {2021},
  month = oct,
  journal = {arXiv:2110.05164 [cs]},
  eprint = {2110.05164},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and AI. First, it provides a critical analysis of current efforts to establish practical mechanisms for algorithmic assessment, which are used to operationalise normative principles, such as sustainability, accountability, transparency, fairness, and explainability, in order to identify limitations and gaps with the current approaches. Second, it provides an accessible introduction to the methodology of argument-based assurance, and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems. Third, it generalises this method to incorporate wider ethical, social, and legal considerations, in turn establishing a novel version of argument-based assurance that we call 'ethical assurance'. Ethical assurance is presented as a structured means for unifying the myriad practical mechanisms that have been proposed, as it is built upon a process-based form of project governance that supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities. Finally, it sets an agenda for ethical assurance, by detailing current challenges, open questions, and next steps, which serve as a springboard to build an active (and interdisciplinary) research programme as well as contribute to ongoing discussions in policy and governance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/cburr/Zotero/storage/SF73AM7A/Burr_Leslie_2021_Ethical Assurance.pdf;/Users/cburr/Zotero/storage/RNDYUN3E/2110.html}
}

@article{burton2020,
  title = {A Systematic Review of Algorithm Aversion in Augmented Decision Making},
  author = {Burton, Jason W. and Stein, Mari-Klara and Jensen, Tina Blegind},
  year = {2020},
  month = apr,
  journal = {Journal of Behavioral Decision Making},
  volume = {33},
  number = {2},
  pages = {220--239},
  issn = {0894-3257, 1099-0771},
  doi = {10.1002/bdm.2155},
  abstract = {Despite abundant literature theorizing societal implications of algorithmic decision making, relatively little is known about the conditions that lead to the acceptance or rejection of algorithmically generated insights by individual users of decision aids. More specifically, recent findings of algorithm aversion\textemdash the reluctance of human forecasters to use superior but imperfect algorithms\textemdash raise questions about whether joint humanalgorithm decision making is feasible in practice. In this paper, we systematically review the topic of algorithm aversion as it appears in 61 peer-reviewed articles between 1950 and 2018 and follow its conceptual trail across disciplines. We categorize and report on the proposed causes and solutions of algorithm aversion in five themes: expectations and expertise, decision autonomy, incentivization, cognitive compatibility, and divergent rationalities. Although each of the presented themes addresses distinct features of an algorithmic decision aid, human users of the decision aid, and/or the decision making environment, apparent interdependencies are highlighted. We conclude that resolving algorithm aversion requires an updated research program with an emphasis on theory integration. We provide a number of empirical questions that can be immediately carried forth by the behavioral decision making community.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/RE2XGAC7/Burton et al_2020_A systematic review of algorithm aversion in augmented decision making.pdf}
}

@article{cadwalladr2017,
  title = {The Great {{British Brexit}} Robbery: How Our Democracy Was Hijacked},
  shorttitle = {The Great {{British Brexit}} Robbery},
  author = {Cadwalladr, Carole},
  year = {2017},
  month = may,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {A shadowy operation involving big data, billionaire friends of Trump and the disparate forces of the Leave campaign heavily influenced the result of the EU referendum. Is our electoral process still fit for purpose?},
  chapter = {Technology},
  langid = {british},
  keywords = {Article 50,Big data,Brexit,Data protection,Dominic Cummings,European Union,Facebook,Foreign policy,Politics,Technology,UK news},
  file = {/Users/cburr/Zotero/storage/4Y392D4H/the-great-british-brexit-robbery-hijacked-democracy.html}
}

@article{collins2002,
  title = {The {{Third Wave}} of {{Science Studies}}: Studies of {{Expertise}} and {{Experience}}},
  shorttitle = {The {{Third Wave}} of {{Science Studies}}},
  author = {Collins, H.M. and Evans, Robert},
  year = {2002},
  month = apr,
  journal = {Social Studies of Science},
  volume = {32},
  number = {2},
  pages = {235--296},
  publisher = {{SAGE Publications Ltd}},
  issn = {0306-3127},
  doi = {10.1177/0306312702032002003},
  abstract = {Science studies has shown us why science and technology cannot always solve technical problems in the public domain. In particular, the speed of political decision-making is faster than the speed of scientific consensus formation. A predominant motif over recent years has been the need to extend the domain of technical decision-making beyond the technically qualified \'elite, so as to enhance political legitimacy. We argue, however, that the `Problem of Legitimacy' has been replaced by the `Problem of Extension' - that is, by a tendency to dissolve the boundary between experts and the public so that there are no longer any grounds for limiting the indefinite extension of technical decision-making rights. We argue that a Third Wave of Science Studies - Studies of Expertise and Experience (SEE) - is needed to solve the Problem of Extension. SEE will include a normative theory of expertise, and will disentangle expertise from political rights in technical decision-making. The theory builds categories of expertise, starting with the key distinction between interactive expertise and contributory expertise. A new categorization of types of science is also needed. We illustrate the potential of the approach by re-examining existing case studies, including Brian Wynne's study of Cumbrian sheep farmers. Sometimes the new theory argues for more public involvement, sometimes for less. An Appendix describes existing contributions to the problem of technical decision-making in the public domain.}
}

@misc{community2019,
  title = {The {{Turing Way}}: A {{Handbook}} for {{Reproducible Data Science}}},
  shorttitle = {The {{Turing Way}}},
  author = {Community, The Turing Way and Arnold, Becky and Bowler, Louise and Gibson, Sarah and Herterich, Patricia and Higman, Rosie and Krystalli, Anna and Morley, Alexander and O'Reilly, Martin and Whitaker, Kirstie},
  year = {2019},
  month = mar,
  doi = {10.5281/ZENODO.3233986},
  abstract = {Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists.{$<$}em{$>$} {$<$}/em{$><$}em{$>$}The Turing Way{$<$}/em{$>$} is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is "too easy not to do". It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. {$<$}strong{$>$}Release log{$<$}/strong{$>$} {$<$}strong{$>$}v0.0.4:{$<$}/strong{$>$} Continuous integration chapter merged to master. {$<$}strong{$>$}v0.0.3:{$<$}/strong{$>$} Reproducible environments chapter merged to master. {$<$}strong{$>$}v0.0.2:{$<$}/strong{$>$} Version control chapter merged to master. {$<$}strong{$>$}v0.0.1: {$<$}/strong{$>$}Reproducibility chapter merged to master.},
  copyright = {Creative Commons Attribution 4.0 International, Open Access},
  howpublished = {Zenodo}
}

@misc{diop2019,
  title = {Explainable {{AI}}: The Data Scientists' New Challenge},
  shorttitle = {Explainable {{AI}}},
  author = {Diop, Mouhamadou-Lamine},
  year = {2019},
  month = aug,
  journal = {Medium},
  abstract = {Authors: Lamine Diop and Jean Cupe},
  howpublished = {https://towardsdatascience.com/explainable-ai-the-data-scientists-new-challenge-f7cac935a5b4},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/UUSUM44M/explainable-ai-the-data-scientists-new-challenge-f7cac935a5b4.html}
}

@misc{duff-brown2017,
  title = {The Shameful Legacy of {{Tuskegee}} Syphilis Study Still Impacts {{African}}-{{American}} Men Today},
  author = {{Duff-Brown}, Beth},
  year = {2017},
  journal = {Stanford Health Policy},
  howpublished = {https://healthpolicy.fsi.stanford.edu/news/researchers-and-students-run-pilot-project-oakland-test-whether-tuskegee-syphilis-trial-last},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/A6CC49DM/researchers-and-students-run-pilot-project-oakland-test-whether-tuskegee-syphilis-trial-last.html}
}

@misc{europeancommission2014,
  type = {Text},
  title = {Responsible Research \& Innovation},
  author = {European Commission},
  year = {2014},
  month = apr,
  journal = {Horizon 2020},
  abstract = {Responsible research \& innovation},
  howpublished = {https://ec.europa.eu/programmes/horizon2020/en/h2020-section/responsible-research-innovation},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/Z7TITN8R/responsible-research-innovation.html}
}

@book{feyerabend1978,
  title = {Science in a Free Society},
  author = {Feyerabend, Paul},
  year = {1978},
  publisher = {{Schocken Books}}
}

@article{floridi2019,
  title = {A {{Unified Framework}} of {{Five Principles}} for {{AI}} in {{Society}}},
  author = {Floridi, Luciano and Cowls, Josh},
  year = {2019},
  month = jun,
  journal = {Harvard Data Science Review},
  doi = {10.1162/99608f92.8cd550d1},
  abstract = {Artificial Intelligence (AI) is already having a major impact on society. As a result, many organizations have launched a wide range of initiatives to establish ethical principles for the adoption of socially beneficial AI. Unfortunately, the sheer volume of proposed principles threatens to overwhelm and confuse. How might this problem of `principle proliferation' be solved? In this paper, we report the results of a fine-grained analysis of several of the highest-profile sets of ethical principles for AI. We assess whether these principles converge upon a set of agreed-upon principles, or diverge, with significant disagreement over what constitutes `ethical AI.' Our analysis finds a high degree of overlap among the sets of principles we analyze. We then identify an overarching framework consisting of five core principles for ethical AI. Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice. On the basis of our comparative analysis, we argue that a new principle is needed in addition: explicability, understood as incorporating both the epistemological sense of intelligibility (as an answer to the question `how does it work?') and in the ethical sense of accountability (as an answer to the question: `who is responsible for the way it works?'). In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/CZZWYA6H/Floridi_Cowls_2019_A Unified Framework of Five Principles for AI in Society.pdf}
}

@article{gigerenzer1991,
  title = {How to {{Make Cognitive Illusions Disappear}}: Beyond ``{{Heuristics}} and {{Biases}}''},
  shorttitle = {How to {{Make Cognitive Illusions Disappear}}},
  author = {Gigerenzer, Gerd},
  year = {1991},
  month = jan,
  journal = {European Review of Social Psychology},
  volume = {2},
  number = {1},
  pages = {83--115},
  issn = {1046-3283, 1479-277X},
  doi = {10.1080/14792779143000033},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/MUGDPRA4/Gigerenzer_1991_How to Make Cognitive Illusions Disappear.pdf}
}

@article{gigerenzer1996,
  title = {On Narrow Norms and Vague Heuristics: A Reply to {{Kahneman}} and {{Tversky}}.},
  author = {Gigerenzer, Gerd},
  year = {1996},
  journal = {Psychological Review},
  volume = {103},
  number = {3},
  pages = {592--596},
  doi = {0.1037/0033-295X.103.3.592}
}

@book{hacking1999,
  title = {The Social Construction of What?},
  author = {Hacking, Ian},
  year = {1999},
  edition = {7. print},
  publisher = {{Harvard Univ. Press}},
  address = {{Cambridge, Mass.}},
  isbn = {978-0-674-00412-2 978-0-674-81200-0},
  langid = {english}
}

@article{hardin1968,
  title = {The {{Tragedy}} of the {{Commons}}},
  author = {Hardin, Garrett},
  year = {1968},
  journal = {Science},
  volume = {162},
  number = {3859},
  pages = {1243--1248},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075}
}

@techreport{hawkins2021,
  title = {Guidance on the {{Assurance}} of {{Machine Learning}} in {{Autonomous Systems}}},
  author = {Hawkins, Richard and Paterson, Colin and Picardi, Chiara and Jia, Yan and Calinescu, Radu and Habli, Ibrahim},
  year = {2021},
  month = mar,
  address = {{University of York}},
  institution = {{Assuring Autonomy International Programme (AAIP)}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/9B4RAFVY/Hawkins et al_2021_Guidance on the Assurance of Machine Learning in Autonomous Systems.pdf}
}

@techreport{ico2020,
  title = {Explaining Decisions Made with {{AI}}},
  author = {ICO and Alan Turing Institute},
  year = {2020},
  month = may,
  institution = {{ICO \& Alan Turing Institute}},
  file = {/Users/cburr/Zotero/storage/GA3GCNA6/ICO_Alan Turing Institute_2020_Explaining decisions made with AI.pdf}
}

@misc{ico2021,
  title = {Guide to {{Data Protection}}},
  author = {ICO},
  year = {2021},
  month = oct,
  publisher = {{ICO}},
  abstract = {This guide is for data protection officers and others who have day-to-day responsibility for data protection. It is aimed at small and medium-sized organisations, but it may be useful for larger organisations too.},
  howpublished = {https://ico.org.uk/for-organisations/guide-to-data-protection/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/EFI4BF9T/guide-to-data-protection.html}
}

@article{jasanoff2009,
  title = {Containing the {{Atom}}: Sociotechnical {{Imaginaries}} and {{Nuclear Power}} in the {{United States}} and {{South Korea}}},
  shorttitle = {Containing the {{Atom}}},
  author = {Jasanoff, Sheila and Kim, Sang-Hyun},
  year = {2009},
  month = jun,
  journal = {Minerva},
  volume = {47},
  number = {2},
  pages = {119--146},
  issn = {0026-4695, 1573-1871},
  doi = {10.1007/s11024-009-9124-4},
  abstract = {STS research has devoted relatively little attention to the promotion and reception of science and technology by non-scientific actors and institutions. One consequence is that the relationship of science and technology to political power has tended to remain undertheorized. This article aims to fill that gap by introducing the concept of ``sociotechnical imaginaries.'' Through a comparative examination of the development and regulation of nuclear power in the US and South Korea, the article demonstrates the analytic potential of the imaginaries concept. Although nuclear power and nationhood have long been imagined together in both countries, the nature of those imaginations has remained strikingly different. In the US, the state's central move was to present itself as a responsible regulator of a potentially runaway technology that demands effective ``containment.'' In South Korea, the dominant imaginary was of ``atoms for development'' which the state not only imported but incorporated into its scientific, technological and political practices. In turn, these disparate imaginaries have underwritten very different responses to a variety of nuclear shocks and challenges, such as Three Mile Island (TMI), Chernobyl, and the spread of the anti-nuclear movement.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7DXMK9JE/Jasanoff and Kim - 2009 - Containing the Atom Sociotechnical Imaginaries an.pdf}
}

@article{jobin2019,
  title = {The Global Landscape of {{AI}} Ethics Guidelines},
  author = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  year = {2019},
  month = sep,
  journal = {Nature Machine Intelligence},
  volume = {1},
  number = {9},
  pages = {389--399},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0088-2},
  abstract = {In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be `ethical', there is debate about both what constitutes `ethical AI' and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.},
  file = {/Users/cburr/Zotero/storage/DUE9LGHC/Jobin et al_2019_The global landscape of AI ethics guidelines.pdf}
}

@article{kahneman1996,
  title = {On the Reality of Cognitive Illusions.},
  author = {Kahneman, Daniel and Tversky, Amos},
  year = {1996},
  journal = {Psychological Review},
  volume = {103},
  number = {3},
  pages = {582--591},
  publisher = {{American Psychological Association}}
}

@article{kang2018,
  title = {Facebook {{Says Cambridge Analytica Harvested Data}} of {{Up}} to 87 {{Million Users}}},
  author = {Kang, Cecilia and Frenkel, Sheera},
  year = {2018},
  month = apr,
  journal = {The New York Times},
  issn = {0362-4331},
  abstract = {Mr. Zuckerberg, Facebook's chief executive, will appear before multiple congressional committees next week. It is part of the company's efforts to be more open about its work.},
  chapter = {Technology},
  langid = {american},
  keywords = {Cambridge Analytica,Data-Mining and Database Marketing,Facebook Inc,Presidential Election of 2016,Russian Interference in 2016 US Elections and Ties to Trump Associates,Trump; Donald J,United States Politics and Government,Zuckerberg; Mark E},
  file = {/Users/cburr/Zotero/storage/IZ9WFSI5/mark-zuckerberg-testify-congress.html}
}

@article{kosinski2013,
  title = {Private Traits and Attributes Are Predictable from Digital Records of Human Behavior},
  author = {Kosinski, M. and Stillwell, D. and Graepel, T.},
  year = {2013},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {15},
  pages = {5802--5805},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1218772110},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/MF2MBLQF/Kosinski et al_2013_Private traits and attributes are predictable from digital records of human.pdf}
}

@book{kuhn1996,
  title = {The Structure of Scientific Revolutions},
  author = {Kuhn, Thomas S.},
  year = {1996},
  edition = {3rd ed},
  publisher = {{University of Chicago Press}},
  address = {{Chicago, IL}},
  isbn = {978-0-226-45807-6 978-0-226-45808-3},
  lccn = {Q175 .K95 1996},
  keywords = {History,Philosophy,Science}
}

@article{larvor2000,
  title = {Review: The {{Social Construction}} of {{What}}?, By {{Ian Hacking}}.},
  author = {Larvor, Brendan},
  year = {2000},
  journal = {Mind},
  volume = {109},
  number = {435},
  pages = {614--618},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/SUPSDZFF/Larvor - 2000 - Review.pdf}
}

@book{latour1986,
  title = {Laboratory Life: The Construction of Scientific Facts},
  shorttitle = {Laboratory Life},
  author = {Latour, Bruno and Woolgar, Steve},
  year = {1986},
  publisher = {{Princeton University Press}},
  address = {{Princeton, N.J}},
  isbn = {978-0-691-02832-3 978-0-691-09418-2},
  lccn = {QH315 .L315 1986},
  keywords = {Biology,Methodology,Research}
}

@book{latour2013,
  title = {Laboratory {{Life}}: The {{Construction}} of {{Scientific Facts}}},
  shorttitle = {Laboratory {{Life}}},
  author = {Latour, Bruno and WooIgar, Steve},
  year = {2013},
  month = apr,
  publisher = {{Princeton University Press}},
  doi = {10.2307/j.ctt32bbxc},
  isbn = {978-1-4008-2041-2 978-0-691-02832-3}
}

@article{leslie2021,
  title = {Artificial Intelligence, Human Rights, Democracy, and the Rule of Law: A Primer},
  shorttitle = {Artificial Intelligence, Human Rights, Democracy, and the Rule of Law},
  author = {Leslie, David and Burr, Christopher and Aitken, Mhairi and Cowls, Josh and Katell, Michael and Briggs, Morgan},
  year = {2021},
  month = mar,
  journal = {arXiv:2104.04147 [cs]},
  eprint = {2104.04147},
  eprinttype = {arxiv},
  primaryclass = {cs},
  doi = {10.5281/zenodo.4639743},
  abstract = {In September 2019, the Council of Europe's Committee of Ministers adopted the terms of reference for the Ad Hoc Committee on Artificial Intelligence (CAHAI). The CAHAI is charged with examining the feasibility and potential elements of a legal framework for the design, development, and deployment of AI systems that accord with Council of Europe standards across the interrelated areas of human rights, democracy, and the rule of law. As a first and necessary step in carrying out this responsibility, the CAHAI's Feasibility Study, adopted by its plenary in December 2020, has explored options for an international legal response that fills existing gaps in legislation and tailors the use of binding and non-binding legal instruments to the specific risks and opportunities presented by AI systems. The Study examines how the fundamental rights and freedoms that are already codified in international human rights law can be used as the basis for such a legal framework. The purpose of this primer is to introduce the main concepts and principles presented in the CAHAI's Feasibility Study for a general, non-technical audience. It also aims to provide some background information on the areas of AI innovation, human rights law, technology policy, and compliance mechanisms covered therein. In keeping with the Council of Europe's commitment to broad multi-stakeholder consultations, outreach, and engagement, this primer has been designed to help facilitate the meaningful and informed participation of an inclusive group of stakeholders as the CAHAI seeks feedback and guidance regarding the essential issues raised by the Feasibility Study.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
  file = {/Users/cburr/Zotero/storage/JYV87CI8/Leslie et al_2021_Artificial intelligence, human rights, democracy, and the rule of law.pdf;/Users/cburr/Zotero/storage/G3KPTMQ9/2104.html}
}

@article{mcguire2020,
  title = {The Road Ahead in Genetics and Genomics},
  author = {McGuire, Amy L. and Gabriel, Stacey and Tishkoff, Sarah A. and Wonkam, Ambroise and Chakravarti, Aravinda and Furlong, Eileen E. M. and Treutlein, Barbara and Meissner, Alexander and Chang, Howard Y. and {L{\'o}pez-Bigas}, N{\'u}ria and Segal, Eran and Kim, Jin-Soo},
  year = {2020},
  month = oct,
  journal = {Nature Reviews Genetics},
  volume = {21},
  number = {10},
  pages = {581--596},
  issn = {1471-0056, 1471-0064},
  doi = {10.1038/s41576-020-0272-6},
  abstract = {In celebration of the 20th anniversary of Nature Reviews Genetics, we asked 12 leading researchers to reflect on the key challenges and opportunities faced by the field of genetics and genomics. Keeping their particular research area in mind, they take stock of the current state of play and emphasize the work that remains to be done over the next few years so that, ultimately, the benefits of genetic and genomic research can be felt by everyone.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/8KMY2U9J/McGuire et al. - 2020 - The road ahead in genetics and genomics.pdf}
}

@article{merton1973,
  title = {The {{Normative Structure}} of {{Science}}},
  author = {Merton, Robert K},
  year = {1973},
  journal = {The sociology of science: Theoretical and empirical investigations},
  pages = {267--278}
}

@article{mittelstadt2019,
  title = {Principles Alone Cannot Guarantee Ethical {{AI}}},
  author = {Mittelstadt, Brent},
  year = {2019},
  month = nov,
  journal = {Nature Machine Intelligence},
  volume = {1},
  number = {11},
  pages = {501--507},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0114-4},
  abstract = {Artificial intelligence (AI) ethics is now a global topic of discussion in academic and policy circles. At least 84 public\textendash private initiatives have produced statements describing high-level principles, values and other tenets to guide the ethical development, deployment and governance of AI. According to recent meta-analyses, AI ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach for the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement.},
  file = {/Users/cburr/Zotero/storage/YJY786MV/Mittelstadt_2019_Principles alone cannot guarantee ethical AI.pdf}
}

@book{molnar2019,
  title = {Interpretable {{Machine Learning}}},
  author = {Molnar, Christoph},
  year = {2019},
  publisher = {{Online}},
  file = {/Users/cburr/Zotero/storage/2NSQJX5C/interpretable-ml-book.html}
}

@book{morozov2013,
  title = {To Save Everything, Click Here: Technology, Solutionism and the Urge to Fix Problems That Don't Exist},
  shorttitle = {To Save Everything, Click Here},
  author = {Morozov, Evgeny},
  year = {2013},
  publisher = {{Allen Lane}},
  address = {{London}},
  isbn = {978-0-241-95769-1 978-1-84614-548-3 978-1-84614-549-0},
  langid = {english}
}

@incollection{muniesa2015,
  title = {Actor-{{Network Theory}}},
  booktitle = {International {{Encyclopedia}} of the {{Social}} \& {{Behavioral Sciences}}},
  author = {Muniesa, Fabian},
  year = {2015},
  pages = {80--84},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-097086-8.85001-1},
  isbn = {978-0-08-097087-5},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/WH83528P/Muniesa_2015_Actor-Network Theory.pdf}
}

@techreport{nationalcommission1979,
  title = {The {{Belmont Report}} - {{Ethical Principles}} and {{Guidelines}} for the {{Protection}} of {{Human Subjects}} of {{Research}}},
  author = {National Commission},
  year = {1979},
  month = apr,
  pages = {10},
  address = {{United States}},
  institution = {{The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/R5BTVNFL/National Commission_1979_The Belmont Report - Ethical Principles and Guidelines for the Protection of.pdf}
}

@misc{nhgri2021,
  title = {Human {{Genome Project FAQ}}},
  author = {NHGRI},
  year = {2021},
  journal = {National Human Genome Research Institute},
  abstract = {Explore frequently asked questions and answers about the Human Genome Project and its impact on the field of genomics.},
  howpublished = {https://www.genome.gov/human-genome-project/Completion-FAQ},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7Y5NSLDQ/Completion-FAQ.html}
}

@article{obermeyer2019,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  month = oct,
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aax2342},
  file = {/Users/cburr/Zotero/storage/DN5D6YII/Obermeyer et al_2019_Dissecting racial bias in an algorithm used to manage the health of populations.pdf}
}

@article{owen2012,
  title = {Responsible Research and Innovation: From Science in Society to Science for Society, with Society},
  shorttitle = {Responsible Research and Innovation},
  author = {Owen, R. and Macnaghten, P. and Stilgoe, J.},
  year = {2012},
  month = dec,
  journal = {Science and Public Policy},
  volume = {39},
  number = {6},
  pages = {751--760},
  issn = {0302-3427, 1471-5430},
  doi = {10.1093/scipol/scs093},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/VYHXLDNM/Owen et al_2012_Responsible research and innovation.pdf}
}

@book{owen2013,
  title = {Responsible Innovation},
  editor = {Owen, Richard and Bessant, J. R. and Heintz, Maggy},
  year = {2013},
  publisher = {{Wiley}},
  address = {{Chichester, West Sussex, United Kingdom}},
  isbn = {978-1-118-55140-0 978-1-118-55139-4 978-1-118-55141-7},
  langid = {english},
  lccn = {HD45},
  keywords = {Environmental aspects,Moral and ethical aspects,New products,Research; Industrial,Technological innovations},
  file = {/Users/cburr/Zotero/storage/Y8VAQRAM/Owen et al_2013_Responsible innovation.pdf}
}

@article{pinch1984,
  title = {The {{Social Construction}} of {{Facts}} and {{Artefacts}}: Or {{How}} the {{Sociology}} of {{Science}} and the {{Sociology}} of {{Technology}} Might {{Benefit Each Other}}},
  shorttitle = {The {{Social Construction}} of {{Facts}} and {{Artefacts}}},
  author = {Pinch, Trevor J. and Bijker, Wiebe E.},
  year = {1984},
  month = aug,
  journal = {Social Studies of Science},
  volume = {14},
  number = {3},
  pages = {399--441},
  publisher = {{SAGE Publications Ltd}},
  issn = {0306-3127},
  doi = {10.1177/030631284014003004},
  abstract = {The need for an integrated social constructivist approach towards the study of science and technology is outlined. Within such a programme both scientific facts and technological artefacts are to be understood as social constructs. Literature on the sociology of science, the science-technology relationship, and technology studies is reviewed. The empirical programme of relativism within the sociology of scientific knowledge and a recent study of the social construction of technological artefacts are combined to produce the new approach. The concepts of `interpretative flexibility' and `closure mechanism', and the notion of `social group' are developed and illustrated by reference to a study of solar physics and a study of the development of the bicycle. The paper concludes by setting out some of the terrain to be explored in future studies.},
  file = {/Users/cburr/Zotero/storage/JKEM6GIP/Pinch_Bijker_1984_The Social Construction of Facts and Artefacts.pdf}
}

@article{polanyi1962,
  title = {The {{Republic}} of Science: Its Political and Economic Theory},
  shorttitle = {The {{Republic}} of Science},
  author = {Polanyi, Michael},
  year = {1962},
  journal = {Minerva},
  volume = {1},
  number = {1},
  pages = {54--73},
  issn = {0026-4695, 1573-1871},
  doi = {10.1007/BF01101453},
  langid = {english}
}

@article{post1990,
  title = {The {{Constitutional Concept}} of {{Public Discourse}}: Outrageous {{Opinion}}, {{Democratic Deliberation}}, and {{Hustler Magazine}} v. {{Falwell}}},
  shorttitle = {The {{Constitutional Concept}} of {{Public Discourse}}},
  author = {Post, Robert C.},
  year = {1990},
  journal = {Harvard Law Review},
  volume = {103},
  number = {3},
  pages = {601--686},
  publisher = {{The Harvard Law Review Association}},
  issn = {0017-811X},
  doi = {10.2307/1341344},
  abstract = {Hustler Magazine v. Falwell is the most recent in a long line of first amendment decisions in which the Supreme Court has extended constitutional protection to outrageous or offensive speech. In this article Professor Post analyzes the theory behind this protection. He argues that speech is defined as outrageous by reference to norms of community life. In the culturally heterogeneous environment of the United States, however, first amendment doctrine functions to facilitate communication among communities, so that a common democratic and public opinion may be formed. For this reason first amendment doctrine demarcates a distinct realm of public discourse that is neutral with respect to the norms of specific communities. Professor Post demonstrates how several important themes in the Falwell opinion follow from this separation of public discourse from community values. In particular he contends that the separation illuminates Falwell's rejection of "outrageousness" and "bad motive" as criteria for the regulation of public discourse, as well as its reliance upon the curious and muddy distinction between fact and opinion. Professor Post notes, however, that the constitutional concept of public discourse is inherently unstable, because speech that violates community norms of civility is perceived as irrational and coercive, and hence as incompatible with public deliberation. Thus first amendment doctrine suspends legal enforcement of the very norms that make rational deliberation possible. Professor Post labels this the "paradox of public discourse," and argues that the paradox accounts for the jagged and uneven course of first amendment doctrine. The article concludes with a discussion of the various methods by which the domain of public discourse may be defined.},
  file = {/Users/cburr/Zotero/storage/7U96JWVM/Post_1990_The Constitutional Concept of Public Discourse.pdf}
}

@article{reverby2001,
  title = {More {{Than Fact}} and {{Fiction}}: Cultural {{Memory}} and the {{Tuskegee Syphilis Study}}},
  shorttitle = {More {{Than Fact}} and {{Fiction}}},
  author = {Reverby, Susan M.},
  year = {2001},
  month = sep,
  journal = {The Hastings Center Report},
  volume = {31},
  number = {5},
  pages = {22},
  issn = {00930334},
  doi = {10.2307/3527701},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/NCDCCXKF/Reverby - 2001 - More Than Fact and Fiction Cultural Memory and th.pdf}
}

@incollection{rohracher2015,
  title = {Science and {{Technology Studies}}, {{History}} Of},
  booktitle = {International {{Encyclopedia}} of the {{Social}} \& {{Behavioral Sciences}}},
  author = {Rohracher, Harald},
  year = {2015},
  pages = {200--205},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-097086-8.03064-6},
  isbn = {978-0-08-097087-5},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/YJGVEBGQ/Rohracher_2015_Science and Technology Studies, History of.pdf}
}

@techreport{selectcommittee2000,
  title = {Science and {{Society}}},
  author = {Select Committee},
  year = {2000},
  month = feb,
  institution = {{House of Lords Select Committee on Science and Technology}},
  langid = {english}
}

@article{spence2013,
  title = {Are Antidepressants Overprescribed?},
  author = {Spence, Des and Reid, Ian C},
  year = {2013},
  journal = {BMJ},
  volume = {346},
  pages = {16--17},
  file = {/Users/cburr/Zotero/storage/JPRLJX2Q/Spence_Reid_2013_Are antidepressants overprescribed.pdf}
}

@article{svoboda2020,
  title = {Deep Learning Delivers Early Detection},
  author = {Svoboda, Elizabeth},
  year = {2020},
  journal = {Nature},
  volume = {587},
  number = {S20-22},
  pages = {3},
  doi = {10.1038/d41586-020-03157-9},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/FQUJC4TR/Stolle - Deep learning delivers early detection.pdf}
}

@book{sweenor2020,
  title = {{{ML Ops}}: Operationalizing {{Data Science}}},
  shorttitle = {{{ML Ops}}},
  author = {Sweenor, David and Hillion, Steven and Rope, Dan and Kannabiran, Dev and Hill, Thomas and O'Connell, Michael},
  year = {2020},
  publisher = {{O'Reilly}},
  abstract = {More than half of the analytics and machine learning (ML) models created by organizations today never make it into production. Instead, many of these ML models do nothing more than provide static insights in a slideshow. If they aren't truly operational, these models can't possibly do what you've trained them to do. This report introduces practical concepts to help data scientists and application engineers operationalize ML models to drive real business change. Through lessons based on numerous projects around the world, six experts in data analytics provide an applied four-step approach-Build, Manage, Deploy and Integrate, and Monitor-for creating ML-infused applications within your organization. You'll learn how to: Fulfill data science value by reducing friction throughout ML pipelines and workflows Constantly refine ML models through retraining, periodic tuning, and even complete remodeling to ensure long-term accuracy Design the ML Ops lifecycle to ensure that people-facing models are unbiased, fair, and explainable Operationalize ML models not only for pipeline deployment but also for external business systems that are more complex and less standardized Put the four-step Build, Manage, Deploy and Integrate, and Monitor approach into action.},
  langid = {english}
}

@article{tversky1974,
  title = {Judgment under Uncertainty: Heuristics and Biases},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1974},
  journal = {Science (New York, N.Y.)},
  volume = {185},
  number = {4157},
  pages = {1124--1131},
  publisher = {{American association for the advancement of science}}
}

@article{tversky1983,
  title = {Extensional versus Intuitive Reasoning: The Conjunction Fallacy in Probability Judgment.},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1983},
  journal = {Psychological review},
  volume = {90},
  number = {4},
  pages = {293},
  publisher = {{American Psychological Association}}
}

@misc{ukri2021,
  title = {Responsible Innovation},
  author = {UKRI},
  year = {2021},
  howpublished = {https://www.ukri.org/about-us/policies-standards-and-data/good-research-resource-hub/responsible-innovation/},
  langid = {american},
  file = {/Users/cburr/Zotero/storage/QPZLBVSD/responsible-innovation.html}
}

@book{vonschomberg2011,
  title = {Towards {{Responsible Research}} and {{Innovation}} in the {{Information}} and {{Communication Technologies}} and {{Security Technologies Fields}}},
  author = {Von Schomberg, Ren{\'e}},
  year = {2011},
  publisher = {{Publications Office of the European Union}},
  isbn = {978-92-79-20404-3}
}

@incollection{ward2020,
  title = {An {{Assurance Case Pattern}} for the {{Interpretability}} of {{Machine Learning}} in {{Safety}}-{{Critical Systems}}},
  booktitle = {Computer {{Safety}}, {{Reliability}}, and {{Security}}. {{SAFECOMP}} 2020 {{Workshops}}},
  author = {Ward, Francis Rhys and Habli, Ibrahim},
  editor = {Casimiro, Ant{\'o}nio and Ortmeier, Frank and Schoitsch, Erwin and Bitsch, Friedemann and Ferreira, Pedro},
  year = {2020},
  volume = {12235},
  pages = {395--407},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-55583-2_30},
  abstract = {Machine Learning (ML) has the potential to become widespread in safety-critical applications. It is therefore important that we have sufficient confidence in the safe behaviour of the ML-based functionality. One key consideration is whether the ML being used is interpretable. In this paper, we present an argument pattern, i.e. reusable structure, that can be used for justifying the sufficient interpretability of ML within a wider assurance case. The pattern can be used to assess whether the right interpretability method and format are used in the right context (time, setting and audience). This argument structure provides a basis for developing and assessing focused requirements for the interpretability of ML in safety-critical domains.},
  isbn = {978-3-030-55582-5 978-3-030-55583-2},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/R97ET6TT/Ward_Habli_2020_An Assurance Case Pattern for the Interpretability of Machine Learning in.pdf}
}

@article{weaver2018,
  title = {Facebook Scandal: I Am Being Used as Scapegoat \textendash{} Academic Who Mined Data},
  shorttitle = {Facebook Scandal},
  author = {Weaver, Matthew},
  year = {2018},
  month = mar,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {Cambridge University researcher Aleksandr Kogan says he is being unfairly blamed by Facebook and Cambridge Analytica},
  chapter = {UK news},
  langid = {british},
  keywords = {Cambridge Analytica,Facebook,Privacy,Social networking,Technology,UK news,University of Cambridge},
  file = {/Users/cburr/Zotero/storage/AYM857FS/facebook-row-i-am-being-used-as-scapegoat-says-academic-aleksandr-kogan-cambridge-analytica.html}
}

@article{wong2005,
  title = {The {{Discovery}} of {{Fluoxetine Hydrochloride}} ({{Prozac}})},
  author = {Wong, David T. and Perry, Kenneth W. and Bymaster, Frank P.},
  year = {2005},
  month = sep,
  journal = {Nature Reviews Drug Discovery},
  volume = {4},
  number = {9},
  pages = {764--774},
  issn = {1474-1776, 1474-1784},
  doi = {10.1038/nrd1821},
  abstract = {In the early 1970s, evidence of the role of serotonin (5-hydroxytryptamine or 5-HT) in depression began to emerge and the hypothesis that enhancing 5-HT neurotransmission would be a viable mechanism to mediate antidepressant response was put forward. On the basis of this hypothesis, efforts to develop agents that inhibit the uptake of 5-HT from the synaptic cleft were initiated. These studies led to the discovery and development of the selective serotoninreuptake inhibitor fluoxetine hydrochloride (Prozac; Eli Lilly), which was approved for the treatment of depression by the US FDA in 1987. Here, we summarize this research and discuss the many challenges that we encountered during the development of fluoxetine hydrochloride, which has now been widely acknowledged as a breakthrough drug for depression.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/LDCRWDKN/Wong et al_2005_The Discovery of Fluoxetine Hydrochloride (Prozac).pdf}
}

@article{yesley2008,
  title = {What's {{ELSI}} Got to Do with It? Bioethics and the {{Human Genome Project}}},
  shorttitle = {What's {{ELSI}} Got to Do with It?},
  author = {Yesley, Michael S.},
  year = {2008},
  month = mar,
  journal = {New Genetics and Society},
  volume = {27},
  number = {1},
  pages = {1--6},
  issn = {1463-6778, 1469-9915},
  doi = {10.1080/14636770701843527},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/SNMF3EP7/Yesley - 2008 - What's ELSI got to do with it Bioethics and the H.pdf}
}

@misc{zotero-9259,
  title = {Personas - {{HackMD}}},
  howpublished = {https://hackmd.io/AMi5IwVHRX2dInvnDyAYfA},
  langid = {british},
  file = {/Users/cburr/Zotero/storage/MDEV3HJ5/AMi5IwVHRX2dInvnDyAYfA.html}
}

@article{zwart2014,
  title = {Adapt or Perish? Assessing the Recent Shift in the {{European}} Research Funding Arena from `{{ELSA}}' to `{{RRI}}'},
  shorttitle = {Adapt or Perish?},
  author = {Zwart, Hub and Landeweerd, Laurens and {van Rooij}, Arjan},
  year = {2014},
  month = dec,
  journal = {Life Sciences, Society and Policy},
  volume = {10},
  number = {1},
  pages = {11},
  issn = {2195-7819},
  doi = {10.1186/s40504-014-0011-x},
  abstract = {Two decades ago, in 1994, in the context of the 4th EU Framework Programme, ELSA was introduced as a label for developing and funding research into the ethical, legal and social aspects of emerging sciences and technologies. Currently, particularly in the context of EU funding initiatives such as Horizon2020, a new label has been forged, namely Responsible Research and Innovation (RRI). What is implied in this metonymy, this semantic shift? What is so new about RRI in comparison to ELSA? First of all, for both labels, the signifier (S) was introduced in a top-down manner, well before the concept that was signified by it (s) had acquired a clear and stable profile. In other words, the signifier preceded (and helped or helps to shape) the research strategies actually covered by these labels (the precedence of the signifier over the signified: S/s). Moreover, the newness of RRI does not reside in its interactive and anticipatory orientation, as is suggested by authors who introduced the term, but rather in its emphases on social-economic impacts (valorisation, employment and competitiveness).},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/ZWY6FUDC/Zwart et al. - 2014 - Adapt or perish Assessing the recent shift in the.pdf}
}


